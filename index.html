<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Primary Meta Tags -->
    <meta name="title"
        content="TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs">
    <meta name="description" content="TimeLens rethinks video temporal grounding (VTG) with MLLMs along two axes: data quality and algorithmic design. We expose critical quality issues in existing VTG benchmarks and propose quality-assured datasets for both training and evaluation. Building upon reliable data, we explore effective timestamp encoding strategies and training recipes, achieving state-of-the-art performance among open-source models.">
    <meta name="keywords" content="video temporal grounding, multimodal LLM, MLLM, multimodal large language models, large language models, RLVR, reinforcement learning, video understanding, computer vision, deep learning, machine learning">
    <!-- TODO: List all authors -->
    <meta name="author" content="Jun Zhang, Teng Wang, Yuying Ge, Yixiao Ge, Xinhao Li, Ying Shan, Limin Wang">
    <meta name="robots" content="index, follow">
    <meta name="language" content="English">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="TimeLens ARC Lab">
    <meta property="og:title" content="TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs">
    <meta property="og:description" content="TimeLens rethinks video temporal grounding (VTG) with MLLMs along two axes: data quality and algorithmic design. We expose critical quality issues in existing VTG benchmarks and propose quality-assured datasets for both training and evaluation. Building upon reliable data, we explore effective timestamp encoding strategies and training recipes, achieving state-of-the-art performance among open-source models.">
    <meta property="og:url" content="https://timelens-arc-lab.github.io/">
    <meta property="og:image" content="https://timelens-arc-lab.github.io/static/images/teaser_v2-1.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:image:alt" content="TimeLens - Research Preview">
    <meta property="article:published_time" content="2025-12-09T00:00:00.000Z">
    <meta property="article:author" content="Jun Zhang">
    <meta property="article:section" content="Research">
    <meta property="article:tag" content="video temporal grounding">
    <meta property="article:tag" content="multimodal LLMs">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs">
    <meta name="twitter:description" content="TimeLens rethinks video temporal grounding (VTG) with MLLMs along two axes: data quality and algorithmic design.">
    <meta name="twitter:image" content="https://timelens-arc-lab.github.io/static/images/teaser_v2-1.png">
    <meta name="twitter:image:alt" content="TimeLens - Research Preview">

    <!-- Academic/Research Specific -->
    <meta name="citation_title" content="TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs">
    <meta name="citation_author" content="Zhang, Jun">
    <meta name="citation_author" content="Wang, Teng">
    <meta name="citation_author" content="Ge, Yuying">
    <meta name="citation_author" content="Ge, Yixiao">
    <meta name="citation_author" content="Li, Xinhao">
    <meta name="citation_author" content="Shan, Ying">
    <meta name="citation_author" content="Wang, Limin">
    <meta name="citation_publication_date" content="2025">
    <meta name="citation_conference_title" content="arXiv">
    <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2512.14698.pdf">

    <!-- Additional SEO -->
    <meta name="theme-color" content="#2563eb">
    <meta name="msapplication-TileColor" content="#2563eb">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="default">

    <!-- Preconnect for performance -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://ajax.googleapis.com">
    <link rel="preconnect" href="https://documentcloud.adobe.com">
    <link rel="preconnect" href="https://cdn.jsdelivr.net">


    <!-- TODO: Replace with your paper title and authors -->
    <title>TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs</title>

    <!-- Favicon and App Icons -->
    <link rel="icon" type="image/png" href="static/images/favicon-32x32.png">
    <link rel="apple-touch-icon" href="static/images/favicon-32x32.png">

    <!-- Critical CSS - Load synchronously -->
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <!-- Non-critical CSS - Load asynchronously -->
    <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
        onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="static/css/bulma-slider.min.css" as="style"
        onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
        onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
        onload="this.onload=null;this.rel='stylesheet'">

    <!-- Fallback for browsers that don't support preload -->
    <noscript>
        <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="static/css/bulma-slider.min.css">
        <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    </noscript>

    <!-- Fonts - Optimized loading -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

    <!-- Defer non-critical JavaScript -->
    <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script defer src="static/js/bulma-carousel.min.js"></script>
    <script defer src="static/js/bulma-slider.min.js"></script>
    <script defer src="static/js/index.js"></script>

    <!-- Structured Data for Academic Papers -->
        <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "ScholarlyArticle",
        "headline": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
        "description": "TimeLens rethinks video temporal grounding (VTG) with MLLMs along two axes: data quality and algorithmic design. We expose critical quality issues in existing VTG benchmarks and propose quality-assured datasets for both training and evaluation. Building upon reliable data, we explore effective timestamp encoding strategies and training recipes, achieving state-of-the-art performance among open-source models.",
        "author": [
            {"@type": "Person", "name": "Jun Zhang", "affiliation": {"@type": "Organization", "name": "Nanjing University"}},
            {"@type": "Person", "name": "Teng Wang", "affiliation": {"@type": "Organization", "name": "ARC Lab, Tencent PCG"}},
            {"@type": "Person", "name": "Yuying Ge", "affiliation": {"@type": "Organization", "name": "ARC Lab, Tencent PCG"}},
            {"@type": "Person", "name": "Yixiao Ge", "affiliation": {"@type": "Organization", "name": "ARC Lab, Tencent PCG"}},
            {"@type": "Person", "name": "Xinhao Li", "affiliation": {"@type": "Organization", "name": "Nanjing University"}},
            {"@type": "Person", "name": "Ying Shan", "affiliation": {"@type": "Organization", "name": "ARC Lab, Tencent PCG"}},
            {"@type": "Person", "name": "Limin Wang", "affiliation": {"@type": "Organization", "name": "Nanjing University; Shanghai AI Lab"}}
        ],
        "datePublished": "2025-12-10",
        "publisher": {"@type": "Organization", "name": "arXiv"},
        "url": "https://timelens-arc-lab.github.io/",
        "image": "https://timelens-arc-lab.github.io/static/images/teaser_v2-1.png",
        "keywords": ["video temporal grounding", "multimodal LLM", "RLVR", "timestamp encoding", "TimeLens-Bench", "TimeLens-100K", "evaluation suite", "dataset refinement"],
        "abstract": "TimeLens rethinks video temporal grounding (VTG) with MLLMs along two axes: data quality and algorithmic design. We expose critical quality issues in existing VTG benchmarks and propose quality-assured datasets for both training and evaluation. Building upon reliable data, we explore effective timestamp encoding strategies and training recipes, achieving state-of-the-art performance among open-source models.",
        "isAccessibleForFree": true,
        "license": "https://creativecommons.org/licenses/by/4.0/",
        "mainEntity": {"@type": "WebPage", "@id": "https://timelens-arc-lab.github.io/"},
        "about": [{"@type": "Thing", "name": "Video Temporal Grounding"}, {"@type": "Thing", "name": "Multimodal Large Language Models"}]
    }
    </script>

    <!-- Website/Organization Structured Data -->
        <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Organization",
        "name": "TimeLens ARC Lab",
        "url": "https://github.com/TimeLens-ARC-Lab",
        "logo": "https://timelens-arc-lab.github.io/static/images/favicon-32x32.png",
        "sameAs": [
            "https://github.com/TimeLens-ARC-Lab"
        ]
    }
    </script>
</head>

<body>


    <!-- Scroll to Top Button -->
    <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
        <i class="fas fa-chevron-up"></i>
    </button>

    <!-- More Works Dropdown -->
    <div class="more-works-container">
        <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Us">
            <i class="fas fa-flask"></i>
            More Research
            <i class="fas fa-chevron-down dropdown-arrow"></i>
        </button>
        <div class="more-works-dropdown" id="moreWorksDropdown">
            <div class="dropdown-header">
                <h4>More Works from Us</h4>
                <button class="close-btn" onclick="toggleMoreWorks()">
                    <i class="fas fa-times"></i>
                </button>
            </div>
            <div class="works-list">
                <!-- TODO: Replace with your lab's related works -->
                <a href="https://arxiv.org/abs/2412.04449" class="work-item" target="_blank">
                    <div class="work-info">
                        <!-- TODO: Replace with actual paper title -->
                        <h5>p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay</h5>
                        <!-- TODO: Replace with brief description -->
                        <p>Efficient MLLM architecture design.</p>
                        <!-- TODO: Replace with venue and year -->
                        <span class="work-venue">ICCV 2025</span>
                    </div>
                    <i class="fas fa-external-link-alt"></i>
                </a>
                <!-- TODO: Add more related works or remove extra items -->
                <a href="https://arxiv.org/abs/2506.01725" class="work-item" target="_blank">
                    <div class="work-info">
                        <h5>VideoCap-R1: Enhancing MLLMs for Video Captioning via Structured Thinking</h5>
                        <p>Reinforcement Learning for MLLM Video Captioners.</p>
                        <span class="work-venue">Arxiv 2025</span>
                    </div>
                    <i class="fas fa-external-link-alt"></i>
                </a>
            </div>
        </div>
    </div>

    <main id="main-content">
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <!-- TODO: Replace with your paper title -->
                            <h1 class="title is-1 publication-title">TimeLens: Rethinking Video Temporal Grounding with
                                Multimodal LLMs</h1>
                            <div class="is-size-5 publication-authors">
                                <!-- TODO: Replace with your paper authors and their personal links -->
                                <span class="author-block">
                                    <a href="https://home.j-zh.top/" target="_blank">Jun Zhang</a><sup>1,2</sup>,</span>
                                <span class="author-block">
                                    <a href="http://ttengwang.com/" target="_blank">Teng Wang</a><sup>2,โ</sup>,</span>
                                <span class="author-block">
                                    <a href="https://geyuying.github.io/" target="_blank">Yuying
                                        Ge</a><sup>2</sup>,</span>
                                <span class="author-block">
                                    <a href="https://geyixiao.com/" target="_blank">Yixiao Ge</a><sup>2</sup>,</span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=evR3uR0AAAAJ"
                                        target="_blank">Xinhao Li</a><sup>1</sup>,</span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en"
                                        target="_blank">Ying Shan</a><sup>2</sup>,</span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=HEuN8PcAAAAJ&hl=en"
                                        target="_blank">Limin Wang</a><sup>1,3,โ</sup>
                                </span>
                            </div>

                            <div class="is-size-5 publication-authors">
                                <!-- TODO: Replace with your institution and conference/journal info -->
                                <span class="author-block"><sup>1</sup>Nanjing University&nbsp;&nbsp;&nbsp;
                                    <sup>2</sup>ARC Lab, Tencent PCG&nbsp;&nbsp;&nbsp;
                                    <sup>3</sup>Shanghai AI Lab<br>arXiv 2025</span>
                            </div>

                            <!-- TODO: Update with your arXiv paper ID -->
                            <span class="link-block">
                                <a href="https://arxiv.org/abs/2512.14698" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper</span>
                                </a>
                            </span>

                            <!-- TODO: Replace with your GitHub repository URL -->
                            <span class="link-block">
                                <a href="https://github.com/TencentARC/TimeLens" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a>
                            </span>

                            <!--Huggingface Link-->
                            <span class="link-block">
                                <a href="https://huggingface.co/collections/TencentARC/timelens" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        ๐ค
                                    </span>
                                    <span>Model & Data</span>
                                </a>
                            </span>

                            <!--Leaderboard Link-->
                            <span class="link-block">
                                <a href="#leaderboard"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-trophy"></i>
                                    </span>
                                    <span>TimeLens-Bench Leaderboard</span>
                                </a>
                            </span>

                        </div>
                    </div>
                </div>
            </div>
            </div>
            </div>
        </section>

        <!-- Overview -->
        <section class="section hero teaser">
            <div class="container is-max-desktop">
                <h2 class="title is-3 has-text-centered">Overview</h2>
                <div class="content is-size-6 has-text-justified has-text-black content-wide">
                    <p>
                        We rethink the key factors for building multimodal large language models (MLLMs) with strong
                        video temporal grounding (VTG) capabilities, along <em>two</em> primary dimensions:
                    </p>
                    <div class="columns is-variable is-6">
                        <div class="column">
                            <h3 class="title is-5"><a href="#data-quality" class="section-link">ยง1</a> Data Quality</h3>
                            <ul>
                                <li><a href="#diagnosing-datasets" class="section-link">ยง1.1</a>Through rigorous diagnosis, we expose <em>critical quality issues</em> in existing VTG datasets.</li>
                                <li><a href="#evaluation-suite" class="section-link">ยง1.2</a>We curate <strong>TimeLens-Bench</strong>, a reliable evaluation suite, via manual refinement on three popular VTG benchmarks. Its necessity is validated by the dramatic model <em>re-rankings</em> observed compared to legacy benchmarks.</li>
                                <li><a href="#training-data" class="section-link">ยง1.3</a>We construct <strong>TimeLens-100K</strong>, a large-scale, high-quality VTG training dataset, via an <em>automated re-annotation</em> pipeline.</li>
                            </ul>
                        </div>
                        <div class="column">
                            <h3 class="title is-5"><a href="#algorithmic-design" class="section-link">ยง2</a> Algorithmic Design</h3>
                            <ul>
                                <li><a href="#timestamp-encoding" class="section-link">ยง2.1</a>For time representation, we find that an <em>interleaved textual prefix</em> is the most effective strategy while maintaining simplicity.</li>
                                <li><a href="#optimization-paradigms" class="section-link">ยง2.2</a>For training paradigm, we demonstrate that a <em>thinking-free</em> reinforcement learning with verifiable rewards (RLVR) approach excels in performance and efficiency.</li>
                                <li><a href="#rl-recipes" class="section-link">ยง2.3</a>For RLVR training recipes, we identify two critical factors for success: <em>early stopping</em> when reward metrics plateau, and <em>difficulty-based</em> data sampling.</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="has-text-centered" style="margin-bottom: 1rem;">
                    <img src="static/images/teaser_v2-1.png" alt="Overview" style="max-width: 60%; height: auto; margin: 0 auto; display: block;" loading="lazy" />
                </div>

                <div class="content is-size-6 has-text-justified has-text-black content-wide">
                    <p>
                        As illustrated below, each of our contributions yields a significant performance gain. These efforts culminate in <strong>TimeLens models</strong>, achieving state-of-the-art VTG performance among open-source models, even surpassing proprietary models like <em>GPT-5</em> and <em>Gemini-2.5-Flash</em>. (Details in our <a href="#leaderboard" style="color: var(--primary-color); font-weight: 600;">Leaderboard</a>)
                    </p>
                </div>

                <div class="has-text-centered" style="margin-top: 1.5rem;">
                    <img src="static/images/ablation_comparison-1.png" alt="Overview" style="max-width: 60%; height: auto; margin: 0 auto; display: block;" loading="lazy" />
                </div>
            </div>
        </section>
        <!-- End teaser video -->

        <!-- Paper abstract -->
        <!-- <section class="section hero is-light">
            <div class="container is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-full">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified is-size-6 has-text-black content-wide">
                            <p>
                                This paper does not introduce a novel method but instead establishes a straightforward,
                                incremental, yet essential baseline for video temporal grounding (VTG), a core
                                capability in video understanding.
                                While multimodal large language models (MLLMs) excel at various video understanding
                                tasks, the recipes for optimizing them for VTG remain under-explored.
                                In this paper, we present <strong>TimeLens</strong>, a systematic investigation into
                                building MLLMs with strong VTG ability, along two primary dimensions: data quality and
                                algorithmic design.
                                We first expose critical quality issues in existing VTG benchmarks and introduce
                                <strong>TimeLens-Bench</strong>, comprising meticulously re-annotated versions of three
                                popular benchmarks with strict quality criteria. Our analysis reveals dramatic model
                                re-rankings compared to legacy benchmarks, confirming the unreliability of prior
                                evaluation standards. We also address noisy training data through an automated
                                re-annotation pipeline, yielding <strong>TimeLens-100K</strong>, a large-scale,
                                high-quality training dataset.
                                Building on our data foundation, we conduct in-depth explorations of algorithmic design
                                principles, yielding a series of meaningful insights and effective yet efficient
                                practices. These include interleaved textual encoding for time representation, a
                                thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the
                                training paradigm, and carefully designed recipes for RLVR training. These efforts
                                culminate in <strong>TimeLens models</strong>, a family of MLLMs with state-of-the-art
                                VTG performance among open-source models and even surpass proprietary models such as
                                GPT-5 and Gemini-2.5-Flash.
                                All codes, data, and models will be released to facilitate future research.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section> -->
        <!-- End paper abstract -->



        <!-- Rethinking Data Quality -->
        <section class="section hero is-light" id="data-quality">
            <div class="container is-max-desktop">
                <h2 class="title is-3 has-text-centered">Rethinking Data Quality</h2>
                <div class="columns is-variable is-8 is-multiline">
                    <div class="column is-full">
                        <h3 class="title is-5" id="diagnosing-datasets">Diagnosing Existing Datasets</h3>
                        <div class="content is-size-6 has-text-justified has-text-black content-wide">
                            <p>
                                We begin by establishing <em>strict quality criteria</em> for VTG annotation, ensuring query clarity, event existence, etc. Based on this, we introduce a rigorous <em>Diagnose-then-Refine</em> pipeline to manually audit and correct existing datasets.
                            </p>
                            <div style="background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%); border-left: 4px solid var(--primary-color); padding: 1rem 1.25rem; margin: 1.5rem 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(37, 99, 235, 0.08);">
                                <p style="margin: 0; font-weight: 500; color: #1e40af; line-height: 1.6;">
                                    <i class="fas fa-lightbulb" style="color: var(--primary-color); margin-right: 0.5rem;"></i>
                                    Applying this pipeline to three widely-used VTG benchmarks <span class="text-small" style="color: #64748b;">(Charades-STA, ActivityNet Captions and QVHighlights)</span>, we expose an <strong style="color: #1e40af;">alarmingly high proportion of errors</strong>.
                                    <br>
                                </p>
                            </div>
                            <p>
                                While the error distribution varies by category, all datasets exhibit consistently high overall error rates.
                            </p>
                        </div>
                        <figure class="image" style="margin-top: .75rem;">
                            <img src="static/images/error_qualitative-1.png" alt="Dataset diagnosis examples" loading="lazy">
                        </figure>
                        <figure class="image" style="margin-top: .75rem; margin-bottom: 2rem;">
                            <img src="static/images/fig4-1.png" alt="Dataset diagnosis statistics" loading="lazy">
                        </figure>
                    </div>
                    <div class="column is-full">
                        <h3 class="title is-5" id="evaluation-suite">TimeLens-Bench: Reliable Evaluation Suite</h3>
                        <div class="content is-size-6 has-text-justified has-text-black content-wide">
                            <p>
                                Through meticulous refinement and correction of the three aforementioned benchmarks, we present <strong>TimeLens-Bench</strong>, a comprehensive evaluation suite featuring both domain diversity and high-quality annotations.
                            </p>
                            <div style="background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%); border-left: 4px solid var(--primary-color); padding: 1rem 1.25rem; margin: 1.5rem 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(37, 99, 235, 0.08);">
                                <p style="margin: 0; font-weight: 500; color: #1e40af; line-height: 1.6;">
                                    <i class="fas fa-lightbulb" style="color: var(--primary-color); margin-right: 0.5rem;"></i>
                                    Benchmarking frontier models on both the original and refined benchmarks reveals <strong style="color: #1e40af;">drastically contrasting performance trends</strong>.
                                </p>
                            </div>

                            <p>
                                On original benchmarks, proprietary models receive poor scores, while performance of open-source model are <strong>deceptively inflated</strong>. Conversely, TimeLens-Bench exposes the true performance gap: proprietary models demonstrate better capabilities, while open-source models suffer substantial performance degradation.
                            </p>
                        </div>
                        <figure class="image has-text-centered" style="margin-top: .75rem;">
                            <img src="static/images/performance_comparison_charades-1.png" alt="TimeLens-Bench" style="max-width: 50%; height: auto; margin: 0 auto; display: block;" loading="lazy">
                        </figure>
                    </div>
                </div>
                <div class="columns is-variable is-8">
                    <div class="column is-full">
                        <h3 class="title is-5" id="training-data">High-Quality Training Data</h3>
                        <div class="content is-size-6 has-text-justified has-text-black content-wide">
                            <p>
                               To address the even more severe noise in large-scale training corpora, we developed an automated re-annotation pipeline powered by <em>Gemini-2.5-Pro</em>. This process yielded <strong>TimeLens-100K</strong>, a large-scale, high-quality VTG training dataset. Compared to original noisy data, TimeLens-100K significantly improves model performance, validating its enhanced quality.
                            </p>
                        </div>
                        <figure class="image has-text-centered" style="margin-top: .75rem;">
                            <img src="static/images/timelens-100k.png" alt="TimeLens-100K" style="max-width: 100%; height: auto;" loading="lazy">
                        </figure>
                    </div>
                </div>
            </div>
        </section>

        <!-- Exploring Algorithmic Designs -->
        <section class="section" id="algorithmic-design">
            <div class="container is-max-desktop">
                <h2 class="title is-3 has-text-centered">Exploring Algorithmic Designs</h2>

                <div class="columns is-variable is-8 is-multiline">
                    <div class="column is-full">
                        <h3 class="title is-5" id="timestamp-encoding">Timestamp Encoding</h3>
                        <div class="content is-size-6 has-text-justified has-text-black content-wide">
                            <p>
                                To enable MLLMs to perform temporal grounding, a critical design decision is <em>timestamp encoding</em> (i.e., aligning the timestamp of each frame with its corresponding features). We conduct a comprehensive comparison of different timestamp encoding methods:
                            </p>
                            <ul>
                                <li>
                                    <strong>Position-embedding based</strong> methods adapt position embeddings in LLMs to represent the temporal position of each frame.
                                </li>
                                <li>
                                    <strong>Visual overlay methods</strong> directly overlay timestamps or frame index onto each frame.
                                </li>
                                <li>
                                    <strong>Textual encoding methods</strong> convert timestamps into text tokens using the MLLM's text tokenizer. There are two main variants: the <em>interleaved</em> approach inserts timestamp tokens before the visual tokens of each frame, while the <em>non-interleaved</em> approach adds an instruction specifying the timestamps of all frames into the prompt.
                                </li>
                            </ul>
                        </div>
                        <figure class="image" style="margin-top: .75rem;">
                            <img src="static/images/time_encode.png" alt="Timestamp encoding illustration" loading="lazy">
                        </figure>

                        <div class="content is-size-6 has-text-justified has-text-black content-wide">
                            <div style="background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%); border-left: 4px solid var(--primary-color); padding: 1rem 1.25rem; margin: 1.5rem 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(37, 99, 235, 0.08);">
                                <p style="margin: 0; font-weight: 500; color: #1e40af; line-height: 1.6;">
                                    <i class="fas fa-lightbulb" style="color: var(--primary-color); margin-right: 0.5rem;"></i>
                                    Our experiments reveal that <strong style="color: #1e40af;">interleaved textual prefix</strong> with raw timestamps achieves the best performance among all approaches, while remaining simple and intuitive.
                                </p>
                            </div>
                        </div>

                        <figure class="image" style="margin-top: .75rem;">
                            <img src="static/images/time_encode_exp.png" alt="Timestamp encoding exp" loading="lazy">
                        </figure>
                    </div>

                    <div class="column is-full">
                        <h3 class="title is-5" id="optimization-paradigms">Optimization Paradigms</h3>
                        <div class="content is-size-6 has-text-justified has-text-black content-wide">
                            <p>
                                Supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR) are the two primary training paradigms for improving MLLMs' VTG capability. However, some key questions remain unanswered:
                            </p>
                            <ul>
                                <li>Under <em>equal training budgets</em> (rather than equal amounts of training data), is RLVR superior to SFT?</li>
                                <li>For VTG, which appears to be a predominantly perception-oriented rather than reasoning-oriented task, is the explicit <em>thinking</em> process in RLVR necessary?</li>
                                <li>Does a <em>preceding SFT phase</em> facilitate subsequent RLVR training by raising the performance ceiling of the final model?</li>
                            </ul>
                            <div style="background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%); border-left: 4px solid var(--primary-color); padding: 1rem 1.25rem; margin: 1.5rem 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(37, 99, 235, 0.08);">
                                <p style="margin: 0; font-weight: 500; color: #1e40af; line-height: 1.6;">
                                    <i class="fas fa-lightbulb" style="color: var(--primary-color); margin-right: 0.5rem;"></i>
                                    Our results reveal that a <strong style="color: #1e40af;">pure thinking-free RLVR</strong> approach maintains simplicity, superior performance, and high efficiency.
                                    <br>
                                    Adding a preceding SFT phase before RLVR yields no significant performance gain.
                                </p>
                            </div>
                        </div>
                        <figure class="image" style="margin-top: .75rem; margin-bottom: 1rem">
                            <img src="static/images/train_paradigm_exp.png" alt="RLVR optimization paradigm" loading="lazy">
                        </figure>
                    </div>

                    <div class="column is-full">
                        <h3 class="title is-5" id="rl-recipes">Effective RL Recipes</h3>
                        <div class="content is-size-6 has-text-justified has-text-black content-wide">
                            <p>
                                Building on the finding that thinking-free RLVR is the optimal training paradigm, we use the TimeLens-100K training corpus to further explore effective recipes for RLVR training, focusing on two key questions:
                            </p>
                        </div>

                        <!-- Early Stopping Subsection -->
                        <div style="margin-top: 1.5rem;">
                            <h4 style="font-size: 1.1rem; font-weight: 500; margin-bottom: 1rem; color: var(--primary-color); border-left: 3px solid var(--primary-color); padding-left: 0.75rem;">(i) How long should we train?</h4>
                            <div class="columns is-variable is-6">
                                <div class="column is-7">
                                    <div class="content is-size-6 has-text-justified has-text-black">
                                        <ul>
                                            <li>We tracked reward metrics and evaluated model checkpoints at different training steps.</li>
                                            <li>When temporal IoU reward and within-group reward standard deviation plateau, model performance peaks.</li>
                                            <li>Continued training beyond this point causes performance degradation.</li>
                                            <li style="background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%); border-left: 3px solid var(--primary-color); padding: 0.75rem 1rem; margin: 0.75rem 0; border-radius: 6px; list-style: none;">
                                                <i class="fas fa-star" style="color: var(--primary-color); margin-right: 0.35rem; font-size: 0.9em;"></i>
                                                <strong style="color: #1e40af;">Best practice:</strong> Perform <strong>early stopping</strong> when reward metrics plateau to save computation and prevent performance degradation.
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="column is-5" style="display: flex; align-items: center; justify-content: center;">
                                    <img src="static/images/training_evaluation_combined-1.png" alt="early_stopping" style="max-width: 100%; height: auto;" loading="lazy" />
                                </div>
                            </div>
                        </div>

                        <!-- Difficulty-based Sampling Subsection -->
                        <div style="margin-top: 2rem;">
                            <h4 style="font-size: 1.1rem; font-weight: 500; margin-bottom: 1rem; color: var(--primary-color); border-left: 3px solid var(--primary-color); padding-left: 0.75rem;">(ii) How to effectively sample training data?</h4>
                            <div class="columns is-variable is-6">
                                <div class="column is-7">
                                    <div class="content is-size-6 has-text-justified has-text-black">
                                        <ul>
                                            <li>We estimate the difficulty of each training sample by running offline inference with the model to be trained and compute IoU metrics.</li>
                                            <li>We sample data from Gaussian distributions with varying means <i>&mu;</i> to obtain training sets of distinct difficulty levels.</li>
                                            <li>Model performance improves with higher average sample difficulty, plateauing at difficulty &gt; 0.75.</li>
                                            <li style="background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%); border-left: 3px solid var(--primary-color); padding: 0.75rem 1rem; margin: 0.75rem 0; border-radius: 6px; list-style: none;">
                                                <i class="fas fa-star" style="color: var(--primary-color); margin-right: 0.35rem; font-size: 0.9em;"></i>
                                                <strong style="color: #1e40af;">Key insight:</strong> Selecting training samples with <strong>sufficiently high difficulty</strong> is crucial for RLVR performance.
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="column is-5" style="display: flex; align-items: center; justify-content: center;">
                                    <img src="static/images/gaussian_filter_vs_expectation-1.png" alt="data_sampling" style="max-width: 100%; height: auto;" loading="lazy" />
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- (Optional) Additional Figures or Analysis - reserved for future content -->

        <!-- Leaderboard Section -->
        <section class="section hero is-light" id="leaderboard">
            <div class="container is-max-desktop">
                <h2 class="title is-3 has-text-centered">TimeLens-Bench Leaderboard</h2>

                <!-- Leaderboard Description -->
                <div class="content is-size-6 has-text-justified has-text-black content-wide" style="margin-bottom: 2rem;">
                    <p>
                        <strong>Instructions for viewing the leaderboard:</strong>
                    </p>
                    <ul>
                        <li>
                            <strong>Separated View vs. Combined View:</strong> The Separated View displays Open-Source and Proprietary models in separate tables. The Combined View shows all models together.
                        </li>
                        <li>
                            <strong>Sort by Metrics:</strong> You can click on any metric column header to sort the models by that specific metric.
                        </li>
                    </ul>
                    <div style="background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%); border-left: 4px solid var(--primary-color); padding: 1rem 1.25rem; margin: 1.5rem 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(37, 99, 235, 0.08);">
                        <p style="margin: 0; font-weight: 500; color: #1e40af; line-height: 1.6;">
                            <i class="fas fa-envelope" style="color: var(--primary-color); margin-right: 0.5rem;"></i>
                            To submit your results to the leaderboard, please contact <a href="mailto:junzhang00@foxmail.com" style="color: #1e40af; font-weight: 600; text-decoration: underline;">junzhang00@foxmail.com</a>.
                        </p>
                    </div>
                </div>

                <!-- View Toggle -->
                <div class="has-text-centered" style="margin-bottom: 2rem;">
                    <div class="buttons is-centered">
                        <button class="button is-primary" id="separatedViewBtn" onclick="switchView('separated')">
                            <span class="icon"><i class="fas fa-layer-group"></i></span>
                            <span>Separated View</span>
                        </button>
                        <button class="button" id="combinedViewBtn" onclick="switchView('combined')">
                            <span class="icon"><i class="fas fa-list"></i></span>
                            <span>Combined View</span>
                        </button>
                    </div>
                </div>

                <!-- Separated View -->
                <div id="separatedView" class="leaderboard-view">
                    <!-- Proprietary Models Table -->
                    <div style="margin-bottom: 3rem;">
                        <h3 class="title is-5" style="margin-bottom: 1rem;">Proprietary Models</h3>
                        <div class="table-container" style="overflow-x: auto;">
                            <table class="table is-striped is-hoverable is-fullwidth leaderboard-table" id="proprietaryTable">
                                <colgroup>
                                    <col style="width:5%">
                                    <col style="width:16%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:7%">
                                </colgroup>
                                <thead>
                                    <tr>
                                        <th class="sortable non-sortable" onclick="sortTable('proprietary', 'rank')" rowspan="2">#</th>
                                        <th class="sortable non-sortable" onclick="sortTable('proprietary', 'model')" rowspan="2">Model</th>
                                        <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">Charades-TimeLens</th>
                                        <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">ActivityNet-TimeLens</th>
                                        <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">QVHighlights-TimeLens</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'avg')" style="font-weight: bold;" rowspan="2">Avg.</th>
                                    </tr>
                                    <tr>
                                        <th class="sortable" onclick="sortTable('proprietary', 'c_r1_03')">R1@<br>0.3</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'c_r1_05')">R1@<br>0.5</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'c_r1_07')">R1@<br>0.7</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'c_miou')">mIoU</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'a_r1_03')">R1@<br>0.3</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'a_r1_05')">R1@<br>0.5</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'a_r1_07')">R1@<br>0.7</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'a_miou')">mIoU</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'q_r1_03')">R1@<br>0.3</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'q_r1_05')">R1@<br>0.5</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'q_r1_07')">R1@<br>0.7</th>
                                        <th class="sortable" onclick="sortTable('proprietary', 'q_miou')">mIoU</th>
                                    </tr>
                                </thead>
                                <tbody id="proprietaryTableBody">
                                    <!-- Data will be populated by JavaScript -->
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <!-- Open-Source Models Table -->
                    <div>
                        <h3 class="title is-5" style="margin-bottom: 1rem;">Open-Source Models</h3>
                        <div class="table-container" style="overflow-x: auto;">
                            <table class="table is-striped is-hoverable is-fullwidth leaderboard-table" id="opensourceTable">
                                <colgroup>
                                    <col style="width:5%">
                                    <col style="width:16%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:6%">
                                    <col style="width:7%">
                                </colgroup>
                                <thead>
                                    <tr>
                                        <th class="sortable non-sortable" onclick="sortTable('opensource', 'rank')" rowspan="2">#</th>
                                        <th class="sortable non-sortable" onclick="sortTable('opensource', 'model')" rowspan="2">Model</th>
                                        <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">Charades-TimeLens</th>
                                        <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">ActivityNet-TimeLens</th>
                                        <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">QVHighlights-TimeLens</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'avg')" style="font-weight: bold;" rowspan="2">Avg.</th>
                                    </tr>
                                    <tr>
                                        <th class="sortable" onclick="sortTable('opensource', 'c_r1_03')">R1@<br>0.3</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'c_r1_05')">R1@<br>0.5</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'c_r1_07')">R1@<br>0.7</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'c_miou')">mIoU</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'a_r1_03')">R1@<br>0.3</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'a_r1_05')">R1@<br>0.5</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'a_r1_07')">R1@<br>0.7</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'a_miou')">mIoU</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'q_r1_03')">R1@<br>0.3</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'q_r1_05')">R1@<br>0.5</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'q_r1_07')">R1@<br>0.7</th>
                                        <th class="sortable" onclick="sortTable('opensource', 'q_miou')">mIoU</th>
                                    </tr>
                                </thead>
                                <tbody id="opensourceTableBody">
                                    <!-- Data will be populated by JavaScript -->
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>

                <!-- Combined View -->
                <div id="combinedView" class="leaderboard-view" style="display: none;">
                    <div class="table-container" style="overflow-x: auto;">
                        <table class="table is-striped is-hoverable is-fullwidth leaderboard-table" id="combinedTable">
                            <colgroup>
                                <col style="width:5%">
                                <col style="width:16%">
                                <col style="width:11%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:5.5%">
                                <col style="width:7%">
                            </colgroup>
                            <thead>
                                <tr>
                                    <th class="sortable non-sortable" onclick="sortTable('combined', 'rank')" rowspan="2">#</th>
                                    <th class="sortable non-sortable" onclick="sortTable('combined', 'model')" rowspan="2">Model</th>
                                    <th class="non-sortable" rowspan="2">Type</th>
                                    <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">Charades-TimeLens</th>
                                    <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">ActivityNet-TimeLens</th>
                                    <th colspan="4" class="has-text-centered benchmark-group" style="background-color: #f5f5f5;">QVHighlights-TimeLens</th>
                                    <th class="sortable" onclick="sortTable('combined', 'avg')" style="font-weight: bold;" rowspan="2">Avg.</th>
                                </tr>
                                <tr>
                                    <th class="sortable" onclick="sortTable('combined', 'c_r1_03')">R1@<br>0.3</th>
                                    <th class="sortable" onclick="sortTable('combined', 'c_r1_05')">R1@<br>0.5</th>
                                    <th class="sortable" onclick="sortTable('combined', 'c_r1_07')">R1@<br>0.7</th>
                                    <th class="sortable" onclick="sortTable('combined', 'c_miou')">mIoU</th>
                                    <th class="sortable" onclick="sortTable('combined', 'a_r1_03')">R1@<br>0.3</th>
                                    <th class="sortable" onclick="sortTable('combined', 'a_r1_05')">R1@<br>0.5</th>
                                    <th class="sortable" onclick="sortTable('combined', 'a_r1_07')">R1@<br>0.7</th>
                                    <th class="sortable" onclick="sortTable('combined', 'a_miou')">mIoU</th>
                                    <th class="sortable" onclick="sortTable('combined', 'q_r1_03')">R1@<br>0.3</th>
                                    <th class="sortable" onclick="sortTable('combined', 'q_r1_05')">R1@<br>0.5</th>
                                    <th class="sortable" onclick="sortTable('combined', 'q_r1_07')">R1@<br>0.7</th>
                                    <th class="sortable" onclick="sortTable('combined', 'q_miou')">mIoU</th>
                                </tr>
                            </thead>
                            <tbody id="combinedTableBody">
                                <!-- Data will be populated by JavaScript -->
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </section>
        <!-- End Leaderboard Section -->




        <!--BibTex citation -->
        <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
                <div class="bibtex-header">
                    <h2 class="title">BibTeX</h2>
                    <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
                        <i class="fas fa-copy"></i>
                        <span class="copy-text">Copy</span>
                    </button>
                </div>
                <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
            </div>
        </section>
        <!--End BibTex citation -->


        <footer class="footer">
            <div class="container">
                <div class="columns is-centered">
                    <div class="column is-8">
                        <div class="content">

                            <p>
                                This page was built using the <a
                                    href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                    target="_blank">Academic Project Page Template</a> which was adopted
                                from theย<a href="https://nerfies.github.io" target="_blank">Nerfies</a>ยproject page.
                                You are free to borrow the source code of this website, we just ask that you
                                link back
                                to this page in the footer. <br> This website is licensed under a <a rel="license"
                                    href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                    Commons Attribution-ShareAlike 4.0 International License</a>.
                            </p>

                        </div>
                    </div>
                </div>
            </div>
        </footer>

        <!-- Statcounter tracking code -->
        <!-- Default Statcounter code for TimeLens https://timelens-arc-lab.github.io/ -->
        <script type="text/javascript">
        var sc_project=13190156;
        var sc_invisible=1;
        var sc_security="ddb994d8";
        </script>
        <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
        <noscript>
            <div class="statcounter">
                <a title="Web Analytics Made Easy - Statcounter" href="https://statcounter.com/" target="_blank">
                    <img class="statcounter" src="https://c.statcounter.com/13190156/0/ddb994d8/1/"
                        alt="Web Analytics Made Easy - Statcounter" referrerPolicy="no-referrer-when-downgrade">
                </a>
            </div>
        </noscript>
        <!-- End of Statcounter Code -->

</body>

</html>